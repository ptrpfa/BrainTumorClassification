{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Brain Tumour Classifier based on DenseNet Transfer learning\n",
    "\n",
    "References:\n",
    "- [Reference 1](https://www.kaggle.com/code/abdoghazala/brain-tumor-detection-classification-cnn-97-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import random\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_FOLDER,\n",
    "    validation_split = 0.2,\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    seed=19032024,\n",
    "    image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    label_mode = 'categorical'\n",
    ")\n",
    "# Validation\n",
    "validate_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_FOLDER,\n",
    "    validation_split = 0.2,\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    seed=19032024,\n",
    "    image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    label_mode = 'categorical'\n",
    "\n",
    ")\n",
    "\n",
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_FOLDER,\n",
    "    shuffle=False,\n",
    "    image_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    label_mode = 'categorical'\n",
    ")\n",
    "\n",
    "# Prefetch the train_dataset\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = training_set.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = training_set.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = training_set.class_names\n",
    "print(class_names)\n",
    "class_names = validate_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View images of dataset\n",
    "class_names = test_set.class_names\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[np.argmax(labels[i])] , c = 'blue' , size = 10)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in validation_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[np.argmax(labels[i])] , c = 'blue' , size = 10)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH) + (3,)\n",
    "LOSS = keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # callbacks for the models\n",
    "# def get_callbacks (model_name):\n",
    "#   callbacks = []\n",
    "#   checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath= f'{model_name}', monitor = 'val_loss', verbose = 1 ,\n",
    "#                                                     mode = 'min', save_best_only=True, save_freq='epoch')\n",
    "#   callbacks.append(checkpoint)\n",
    "#   rlr = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss', factor=0.2, patience=5, mode='auto', min_lr=0.0)\n",
    "#   callbacks.append(rlr)\n",
    "#   earlystop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 7)\n",
    "#   callbacks.append(earlystop)\n",
    "\n",
    "#   return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plot resultes\n",
    "\n",
    "def plot():\n",
    "   pd.DataFrame(history.history)[['categorical_accuracy','val_categorical_accuracy','loss','val_loss']].plot( figsize=(7, 5), xlim=[0, 9], ylim=[0, 1], grid=True, xlabel=\"Epoch\", style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "   plt.show()\n",
    "\n",
    "# for make dataframe for densenet model\n",
    "model_name= 'DenseNet121'\n",
    "CategoricalAccuracy= []\n",
    "losses= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densenet Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "train_dataset_densenet = train_dataset.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "validation_dataset_densenet = validation_dataset.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset_densenet = test_set.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "dense_model = DenseNet121(weights='imagenet', include_top=False, input_shape= IMG_SHAPE , classes = 4)\n",
    "dense_model.trainable = False\n",
    "\n",
    "x = dense_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=dense_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer= OPTIMIZER, loss= LOSS, metrics=[keras.metrics.CategoricalAccuracy() , keras.metrics.Recall()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = get_callbacks('DenseNet121')\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset_densenet,\n",
    "    epochs=10,\n",
    "    validation_data=validation_dataset_densenet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()\n",
    "\n",
    "# Test metrics\n",
    "loss, categorical_accuracy, recall = model.evaluate(test_dataset_densenet)\n",
    "CategoricalAccuracy.append(categorical_accuracy)\n",
    "losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "save_dir = 'model/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(save_dir, 'densenet121.keras'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midnight Maximum Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_tuning = keras.models.load_model('./model/densenet121.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in densenet_tuning.layers[:17]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Set last 5 layers to be trainable\n",
    "for layer in densenet_tuning.layers[17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "history = densenet_tuning.fit(\n",
    "    train_dataset_densenet,\n",
    "    epochs = 10,\n",
    "    validation_data = validation_dataset_densenet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, categorical_accuracy = densenet_tuning.evaluate(test_dataset_densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation in confusion matrix\n",
    "y_true = np.concatenate([ y for _ , y in test_set] , axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_true, axis=1)\n",
    "y_pred = densenet_tuning.predict(test_dataset_densenet)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report , ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_true , y_pred)\n",
    "plt.title(\"Confusion Matrix\", fontname = \"monospace\", fontsize = 15, weight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\\n\")\n",
    "print(Fore.BLUE + classification_report(y_true, y_pred, target_names = class_names, digits= 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
